# Проект 5.  Предсказывание продолжительности поездки на такси в Нью-Йорке.

## Оглавление
[1. Описание проекта](https://github.com/murattumov/project5/blob/master/README.md#Описание-проекта)

[2. Какой кейс решаем?](https://github.com/murattumov/project5/blob/master/README.md#Какой-кейс-решаем)

[3. Краткая информация о данных](https://github.com/murattumov/project5/blob/master/README.md#Краткая-информация-о-данных)

[4. Этапы работы над проектом](https://github.com/murattumov/project5/blob/master/README.md#Этапы-работы-над-проектом)

[5. Результат](https://github.com/murattumov/project5/blob/master/README.md#Результат)

[6. Краткая информация](https://github.com/murattumov/project5/blob/master/README.md#Краткая-информация)

### **Описание проекта**

Предоставлен набор данных, содержащий информацию о поездках на жёлтом такси в Нью-Йорке за 2016 год. Первоначально данные были выпущены Комиссией по Такси и Лимузинам Нью-Йорка и включают в себя информацию о времени поездки, географических координатах, количестве пассажиров и несколько других переменных. Стоимость такси в США рассчитывается на основе фиксированной ставки и тарифной стоимости, величина которой зависит от времени и расстояния. Тарифы варьируются в зависимости от города.
В свою очередь, время поездки зависит от множества факторов, таких как направление поездки, время суток, погодные условия и так далее.
Разработав алгоритм, способный определять длительность поездки, мы сможем прогнозировать её стоимость самым тривиальным образом, например, просто умножая стоимость на заданный тариф.

### **Какой кейс решаем?**
Построить модель машинного обучения, которая на основе предложенных характеристик клиента будет предсказывать числовой признак — время поездки такси, то есть решить задачу регрессии.
Сформировать набор данных на основе нескольких источников информации. Спроектировать новые признаки с помощью Feature Engineering и выявить наиболее значимые при построении модели. Исследовать предоставленные данные и выявить закономерности. Построить несколько моделей и выбрать из них ту, которая показывает наилучший результат по заданной метрике. Спроектировать процесс предсказания длительности поездки для новых данных.

### **Краткая информация о данных**
у нас есть данные о почти 1.5 миллионах поездок и 11 характеристиках, которые описывают каждую из поездок.
Данные о клиенте и таксопарке:

- id — уникальный идентификатор поездки;
- vendor_id — уникальный идентификатор поставщика услуг (таксопарка), связанного с записью поездки.

Временные характеристики:

- pickup_datetime — дата и время, когда был включён счётчик поездки;
- dropoff_datetime — дата и время, когда счётчик был отключён.

Географическая информация:

- pickup_longitude — долгота, на которой был включён счётчик;
- pickup_latitude — широта, на которой был включён счётчик;
- dropoff_longitude — долгота, на которой счётчик был отключён;
- dropoff_latitude — широта, на которой счётчик был отключён.

Прочие признаки:

- passenger_count — количество пассажиров в транспортном средстве (введённое водителем значение);
- store_and_fwd_flag — флаг, который указывает, сохранилась ли запись о поездке в памяти транспортного средства перед отправкой поставщику (Y — хранить и пересылать, N — не хранить и не пересылать поездку).

Целевой признак:

- trip_duration — продолжительность поездки в секундах.


### **Этапы работы над проектом**

- Знакомство с данными, базовый анализ и расширение данных
  1. Переведя признак pickup_datetime в тип данных datetime определяем что данные представлены за период от 2016-01-01 00:00:17
до 2016-06-30 23:59:39.
  2. Пропущенных значений в признаках нет.
  3. Из признака pickup_datetime в таблицу добавляем 3 столбца:
    pickup_date - дата включения счетчика - начала поездки (без времени);
    pickup_hour - час дня включения счетчика;
    pickup_day_of_week - наименование дня недели, в который был включен счетчик.
  4. Загрузив таблицу с данными о праздничных днях добавляем признак pickup_holiday - с бинарным признаком того, начата ли поездка в праздничный день или нет (1 - да, 0 - нет).
  5. Загрузив таблицу с данными из OSRM (ресурс, предполагающий построение кратчайшего маршрута) добавляем в таблицу с данными о поездках 3 столбца:
    total_distance - кратчайшее дорожное расстояние (в метрах);
    total_travel_time - наименьшее время поездки (в секундах);
    number_of_steps - количество дискретных шагов, которые должен выполнить водитель (поворот налево/поворот направо/ехать прямо и т. д.).
  6. С помощью географических координатов вычисляем и добавляем новые признаки:
    haversine_distance — расстояние по формуле гаверсинуса между точкой, в которой был включён счетчик, и точкой, в которой счётчик был выключен;
    direction — направление движения из точки, в которой был включён счётчик, в точку, в которой счётчик был выключен.
  7. Воспользуемся алгоритмом K-Means и обучим его на данных, сформированных из широты и долготы всех точек начала и конца поездок на десять кластеров. В таблицу добавляем признак geo_cluster.
  8. Загрузив таблицу с данными о погодных условиях на каждый час обновляем таблицу с данными о поездках с добавлением в нее 5 столбцов:
    temperature - температура;
    visibility - видимость;
    wind speed - средняя скорость ветра;
    precip - количество осадков;
    events - погодные явления.
  9. Обработка пропусков. Пропуски в столбцах с погодными условиями - temperature, visibility, wind speed, precip заполняем медианным значением температуры, влажности, скорости ветра и видимости в зависимости от даты начала поездки. Пропуски в столбце events заполняем строкой 'None' - символом отсутствия погодных явлений (снега/дождя/тумана). Пропуски в столбцах с информацией из OSRM API - total_distance, total_travel_time и number_of_steps заполните медианным значением по столбцам.
  10. Убираем очевидные выбросы в целевой переменной - длительности поездки, значения trip_duration, которые меньше total_travel_time(либо реальные выбросы, либо с нарушением ПДД). 
  ![](https://github.com/murattumov/project5/blob/master/plotly/pr5_0.png)
  Также по методу z-отклонений удаляем выбросы в признаках: trip_duration, total_travel_time, avg_speed. В результате ослось записей: 1395120.
  ![](https://github.com/murattumov/project5/blob/master/plotly/pr5_01.png)
  ![](https://github.com/murattumov/project5/blob/master/plotly/pr5_02.png)
  ![](https://github.com/murattumov/project5/blob/master/plotly/pr5_03.png)
  


- Разведывательный анализ данных (EDA)

  1. логарифмируем признак длительности поездки trip_duration и при анализе будем рассматривать логарифм в качестве целевого признака.
  Также логарифмируем признак total_travel_time - наименьшее время поездки.
  2. строим гистограмму и коробчатую диаграмму длительности поездок в логарифмическом масштабе (trip_duration_log). Сравниваем распределение по визуализации и с помощью теста Д’Агостино на нормальность.
  ![](https://github.com/murattumov/project5/blob/master/plotly/pr5_1.png)
  ![](https://github.com/murattumov/project5/blob/master/plotly/pr5_2.png)
  3. визуализации распределения длительности поездки в логарифмическом масштабе (trip_duration_log) в зависимости от таксопарка (vendor_id).
  ![](https://github.com/murattumov/project5/blob/master/plotly/pr5_3.png)
  ![](https://github.com/murattumov/project5/blob/master/plotly/pr5_4.png)
  4. визуализации распределения длительности поездки в логарифмическом масштабе (trip_duration_log) в зависимости от признака отправки сообщения поставщику (store_and_fwd_flag).
  ![](https://github.com/murattumov/project5/blob/master/plotly/pr5_5.png)
  ![](https://github.com/murattumov/project5/blob/master/plotly/pr5_6.png)
  5. визуализации:
     -распределение количества поездок в зависимости от часа дня;
     -зависимость медианной длительности поездки от часа дня.
  ![](https://github.com/murattumov/project5/blob/master/plotly/pr5_7.png)
  ![](https://github.com/murattumov/project5/blob/master/plotly/pr5_8.png)

  6. визуализации:
     -распределение количества поездок в зависимости от дня недели;
     -зависимость медианной длительности поездки от дня недели.
     ![](https://github.com/murattumov/project5/blob/master/plotly/pr5_9.png)
     ![](https://github.com/murattumov/project5/blob/master/plotly/pr5_10.png)

  7. тепловая карта сводной таблицы, по строкам которой отложены часы (pickup_hour), по столбцам - дни недели (pickup_day_of_week), а в ячейках - медианная длительность поездки (trip_duration).
  ![](https://github.com/murattumov/project5/blob/master/plotly/pr5_11.png)
  8. две диаграммы рассеяния (scatter-диаграммы):
     -первая должна иллюстрировать географическое расположение точек начала поездок (pickup_longitude, pickup_latitude)
     -вторая должна географическое расположение точек завершения поездок (dropoff_longitude, dropoff_latitude).
     ![](https://github.com/murattumov/project5/blob/master/plotly/pr5_12.png)
     ![](https://github.com/murattumov/project5/blob/master/plotly/pr5_13.png)

  
- Отбор и преобразование признаков
  1. избавляемся от неинформативных и избыточных признаков: 'id', 'dropoff_datetime', 'pickup_datetime', 'pickup_date', 
  2. закодируем признак store_and_fwd_flag таким образом, чтобы он был равен 0, если флаг выставлен в значение 'N', и 1 — в противном случае.
  3. кодирование категориальные признаки pickup_day_of_week, geo_cluster, 'pickup_hour', 'vendor_id' и events с помощью get_dummies.
  4. сформируем матрицу наблюдений X, вектор целевой переменной y и его логарифм y_log. В матрицу наблюдений войдут все столбцы из таблицы с поездками за исключением целевого признака trip_duration и его логарифмированной версии trip_duration_log.
  5. разбиваем выборку на обучающую и валидационную в соотношении 67/33 с помощью train_test_split.
  6. нормализуем предикторы в обучающей и валидационной выборках с помощью RobustScaler из библиотеки sklearn.


- Решение задачи регрессии: линейная регрессия и деревья решений  
  1. строим модель линейной регрессии на обучающей выборке (целевая переменная используется в логарифмическом масштабе). Все параметры по умолчанию. В качестве метрики используется RMSLE. Получаем метрики на тренировочной - 0.34 и валидационной выборке равной 0.34.
  2. строим модель дерева решений (DecisionTreeRegressor) на обучающей выборке (целевую переменную используйте в логарифмическом масштабе). Все параметры по умолчанию. Для полученной модели рассчитываем метрику RMSLE для валидационной выборки и получаем 0.41. 
  3. перебераем все возможные варианты глубины дерева решений в диапазоне от 7 до 20. Находим оптимальное значение максимальной глубины дерева равной 12 и получаем метрики на тренировочной и валидационной выборках: 0.33 и 0.34 соответственно.
  ![](https://github.com/murattumov/project5/blob/master/plotly/pr5_14.png)

- Решение задачи регрессии: ансамблевые методы и построение прогноза
  1. строим модель случайного леса на обучающей выборке (целевую переменную используйте в логарифмическом масштабе). В качестве гиперпараметров используем следующие:
    n_estimators=200,
    max_depth=12,
    criterion='squared_error',
    min_samples_split=20,
    random_state=42
  Получаем метрику RMSLE на тренировочной и валидационной выборках: 0.32 и 0.33

  2. строим модель градиентного бустинга над деревьями решений (GradientBoostingRegressor) на обучающей выборке (целевую переменную используйте в логарифмическом масштабе). В качестве гиперпараметров используем следующие:
    learning_rate=0.5,
    n_estimators=100,
    max_depth=6,
    min_samples_split=30,
    random_state=42
    Получаем метрику RMSLE на тренировочной и валидационной выборках: 0.21 и 0.28

  6. по наилучшему моделю, модель градиентного бустинга над деревьями решений, строим столбчатую диаграмму коэффициентов значимости каждого из факторов. Наилучшие топ-3 факторы: total_distance, total_travel_time и dropoff_latitude.
  ![](https://github.com/murattumov/project5/blob/master/plotly/pr5_15.png)
  7. получаем более понятное представление об ошибке прогноза длительности поездки с помощью медианной абсолютной ошибки (MeAE - в sklearn функция median_absolute_error) предсказания длительности поездки такси на тренировочной и валидационной выборке. Получаем значение в минутах: 1.35 и 1.79.
  8. используем модель экстремального градиентного бустинга (XGBoost) из библиотеки xgboost. Гиперпараметры модели:
      'min_child_weight': 20, 'eta': 0.1, 'colsample_bytree': 0.9,
      'max_depth': 12, 'subsample': 0.9, 'lambda': 1, 'nthread': -1,
      'booster' : 'gbtree', 'eval_metric': 'rmse', 'objective': 'reg:squarederror',
      'alpha' : 0.1, 'lambda' : 10
  Получаем метрику RMSLE на тренировочной и валидационной выборках: 0.21	и 0.26.
  9. строим столбчатую диаграмму коэффициентов значимости каждого из факторов. Наилучшие топ-10 факторов: pickup_latitude, dropoff_latitude, dropoff_longitude, pickup_longitude, direction, haversine_distance, total_travel_time, total_distance, temperature,  wind speed.
  ![](https://github.com/murattumov/project5/blob/master/plotly/pr5_16.png)


### **Результат**

Из 11 исходных признаков в топ-10 признаков для построения модели попало 4. Остальные - это признаки, сконструированные в процессе исследования данных. Используя модель экстремального градиентного бустинга (XGBoost) из библиотеки xgboost получли наилучшую метрику RMSLE на тренировочной и валидационной выборках: 0.21	и 0.26 соответсвенно. Гиперпараметры модели:
      'min_child_weight': 20, 'eta': 0.1, 'colsample_bytree': 0.9,
      'max_depth': 12, 'subsample': 0.9, 'lambda': 1, 'nthread': -1,
      'booster' : 'gbtree', 'eval_metric': 'rmse', 'objective': 'reg:squarederror',
      'alpha' : 0.1, 'lambda' : 10

### **Краткая информация**

****


:arrow_up:[к оглавлению](https://github.com/murattumov/project5/blob/master/README.md#Оглавление)
